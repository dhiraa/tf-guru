{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"TFRecord\"\n",
    "description: \"Working with TensorFlow TFRecords\"\n",
    "excerpt: \"Working with TensorFlow TFRecords\"\n",
    "date:   2017-11-11\n",
    "mathjax: true\n",
    "comments: true \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter notebook avaialble @ [www.github.com/iaja/tf-guru/dataset/2017-11-11-TFRecord.ipynb](www.github.com/iaja/tf-guru/dataset/2017-11-11-TFRecord-DatasetHandling.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data: [Use tf.SequenceExample](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto)\n",
    "\n",
    "```\n",
    "Data ---> Preprocessing ---> TFRecords ---> Input Graph ---> Model\n",
    "```\n",
    "\n",
    "RNNs are used for sequential data that has inputs and/or outputs at multiple time steps. Tensorflow comes with a protocol buffer definition to deal with such data: `tf.SequenceExample`.\n",
    "\n",
    "\n",
    "You can load data directly from your Python/Numpy arrays, but it’s probably in your best interest to use tf.SequenceExample instead. This data structure consists of a “context” for non-sequential features and “feature_lists” for sequential features. It’s somewhat verbose (it blew up my latest dataset by 10x), but it comes with a few benefits that are worth it:\n",
    "\n",
    "- **Easy distributed training.** Split up data into multiple TFRecord files, each containing many SequenceExamples, and use Tensorflow’s built-in support for distributed training.\n",
    "- **Reusability.** Other people can re-use your model by bringing their own data into tf.SequenceExample format. No model code changes required.\n",
    "- **Use of Tensorflow data loading pipelines functions like tf.parse_single_sequence_example.** Libraries like tf.learn also come with convenience function that expect you to feed data in protocol buffer format.\n",
    "- **Separation of data preprocessing and model code.** Using tf.SequenceExample forces you to separate your data preprocessing and Tensorflow model code. This is good practice, as your model shouldn’t make any assumptions about the input data it gets.\n",
    "\n",
    "\n",
    "In practice, you write a little script that converts your data into tf.SequenceExample format and then writes one or more TFRecord files. These TFRecord files are parsed by Tensorflow to become the input to your model:\n",
    "\n",
    "- Convert your data into tf.SequenceExample format\n",
    "- Write one or more TFRecord files with the serialized data\n",
    "- Use tf.TFRecordReader to read examples from the file\n",
    "- Parse each example using tf.parse_single_sequence_example (Not in the official docs yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sequences = [[1, 2, 3], [4, 5, 1], [1, 2]]\n",
    "label_sequences = [[0, 1, 0], [1, 0, 0], [1, 1]]\n",
    "\n",
    "def make_example(sequence, labels):\n",
    "    # The object we return\n",
    "    example_sequence = tf.train.SequenceExample()\n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length = len(sequence)\n",
    "    example_sequence.context.feature[\"length\"].int64_list.value.append(sequence_length)\n",
    "    # Feature lists for the two sequential features of our example\n",
    "    fl_tokens = example_sequence.feature_lists.feature_list[\"tokens\"]\n",
    "    fl_labels = example_sequence.feature_lists.feature_list[\"labels\"]\n",
    "    for token, label in zip(sequence, labels):\n",
    "        fl_tokens.feature.add().int64_list.value.append(token)\n",
    "        fl_labels.feature.add().int64_list.value.append(label)\n",
    "    return example_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A single serialized example\n",
    "# (You can read this from a file using TFRecordReader)\n",
    "example_sequence = make_example([1, 2, 3], [0, 1, 0]).SerializeToString()\n",
    "\n",
    "# Define how to parse the example\n",
    "context_features = {\n",
    "    \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features = {\n",
    "    \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64), #tf.VarLenFeature(tf.int64),\n",
    "    \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the example (returns a dictionary of tensors)\n",
    "context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "    serialized=example_sequence,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': array([0, 1, 0]), 'tokens': array([1, 2, 3])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(context_parsed)\n",
    "sess.run(sequence_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all examples into a TFRecords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_into_tfrecord(sequences, label_sequences):\n",
    "    with tempfile.NamedTemporaryFile() as fp:\n",
    "        \n",
    "        writer = tf.python_io.TFRecordWriter(fp.name)\n",
    "        #get each sequence along with its labels and write it to a file as Sequence Example.\n",
    "        for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "            example_sequence = make_example(sequence, label_sequence)\n",
    "            writer.write(example_sequence.SerializeToString())\n",
    "        \n",
    "        writer.close()\n",
    "        print(\"Wrote to {}\".format(fp.name))\n",
    "        return fp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to /tmp/tmpznwjka42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpznwjka42'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = save_into_tfrecord(sequences, label_sequences)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode_single_example(filename):\n",
    "\n",
    "    filename_queue = tf.train.string_input_producer([filename],\n",
    "                                                num_epochs=None)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    # Define how to parse the example\n",
    "    context_features = {\n",
    "        \"length\": tf.FixedLenFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64), #tf.VarLenFeature(tf.int64),\n",
    "        \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "\n",
    "\n",
    "    return serialized_example, context_features, sequence_features\n",
    "\n",
    "example_sequence,context_features,sequence_features = read_and_decode_single_example(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the example (returns a dictionary of tensors)\n",
    "context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "    serialized=example_sequence,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(context_parsed)\n",
    "sess.run(sequence_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert this notebook for Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 2017-11-11-TFRecord.ipynb to markdown\n",
      "[NbConvertApp] Writing 6351 bytes to ../docs/_posts/2017-11-11-TFRecord.md\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to markdown --output-dir ../docs/_posts 2017-11-11-TFRecord.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
